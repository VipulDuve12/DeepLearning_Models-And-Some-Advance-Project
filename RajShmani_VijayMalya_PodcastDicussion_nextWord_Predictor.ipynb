{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osNC9uaYhszp"
      },
      "outputs": [],
      "source": [
        "podcast = \"\"\"In a groundbreaking episode of his podcast “Figuring Out,” Raj Shamani sat down for an unprecedented four-hour conversation with Vijay Mallya — the controversial business tycoon and former owner of Kingfisher Airlines. This marked Mallya’s first full-length public appearance in nearly nine years, generating massive attention across India and abroad. The podcast delves deep into Mallya’s rise, fall, and his side of the story — much of which has remained unheard due to his prolonged absence from Indian media and the ongoing legal controversies.\n",
        "Rise and Fall of Kingfisher Airlines\n",
        "Mallya gave a detailed account of how Kingfisher Airlines, which began with a vision of luxury air travel in India, eventually collapsed under financial strain. He pointed to a combination of unfortunate events and structural issues as the root causes of the failure. He highlighted the 2008 global financial crisis, rising fuel costs, harsh regulatory conditions in India, and a lack of support from government bodies. He claimed that bureaucratic hurdles, like needing the support of multiple state-level authorities (29 Chief Ministers, as he mentioned), made it impossible to streamline operations.\n",
        "On Being Branded a Fugitive\n",
        "Mallya was particularly emotional and candid when discussing his label as a \"fugitive economic offender.\" He said he left India in March 2016 for a pre-scheduled business trip, not to abscond. He took issue with being called a \"chor\" (thief) by media and the public, insisting that while the airlines failed, there was no criminal intent or theft involved. He added that this label has been deeply hurtful, especially when he’s been trying to settle dues.\n",
        "Loan Repayment & Legal Battles\n",
        "One of the central points of the interview was Mallya’s claim that he had made several genuine offers to Indian banks to repay the loans. According to him, between 2012 and 2015, he proposed four settlement deals — one of which was for ₹14,000 crore — but all were rejected. He stressed that he has already paid back around ₹6,200 crore through the sale of assets and other means, and still questions why the Indian authorities are unwilling to resolve the matter fairly. Mallya emphasized that he never intended to default and wanted a resolution, but he believes political motives complicated the case.\n",
        "Life in Exile\n",
        "Describing his life in London, Mallya admitted that despite the perception of living in luxury, he feels deeply isolated. He talked about the emotional toll of being away from his country and family, saying this period of exile has been the “loneliest” phase of his life. He described his current life as “semi-retired,” where he’s staying busy but far from the flamboyant lifestyle he was once known for.\n",
        "Cultural Influence & the Kingfisher Brand\n",
        "In a lighter segment of the podcast, Mallya looked back at the cultural impact of the Kingfisher brand, especially the Kingfisher Calendar. He proudly noted how it helped launch the careers of now-superstars like Deepika Padukone and Katrina Kaif. According to him, the calendar was a branding masterpiece that gave young models a glamorous, mainstream launchpad into Bollywood and the fashion world.\n",
        "On Royal Challengers Bangalore (RCB)\n",
        "The conversation also touched on his ownership of the IPL team Royal Challengers Bangalore. Mallya shared behind-the-scenes stories of managing the team and expressed pride in how far it has come. While he no longer has a formal association with RCB, he reflected fondly on building the team’s early brand and fan base.\n",
        "Will He Return to India?\n",
        "Perhaps the most significant revelation was Mallya's willingness to return to India — but only if he is assured of a fair and just legal process. He said that while he does not fear facing trial, his main concern lies with the conditions of Indian prisons, citing how UK courts have previously blocked extraditions due to concerns over the state of Indian jails. He added that if the Indian government could guarantee humane conditions and an unbiased trial, he would seriously consider returning to clear his name.\n",
        "Public Reaction and Impact\n",
        "The podcast went viral almost instantly, with millions of views within the first 24 hours. Social media users were split — while some expressed newfound sympathy and praised Raj Shamani for hosting such a fearless and deep conversation, others criticized the platforming of someone declared a fugitive by Indian authorities. Comedians and influencers also jumped into the conversation, with viral parodies and takes emerging from all corners of the internet.\n",
        "In essence, this podcast gave Vijay Mallya the platform to present his version of events — something he claims he’s long been denied by mainstream media. For Raj Shamani, it was a massive leap in credibility as a creator and interviewer, signaling a new era where digital platforms can rival traditional journalism in depth, access, and reach.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "sVxr8MtRh5a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()"
      ],
      "metadata": {
        "id": "jO9g_3WXiMTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.fit_on_texts([podcast])"
      ],
      "metadata": {
        "id": "jnGOIgoDiSHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9IqPLwXiVnz",
        "outputId": "05f13031-9356-4b93-ab15-b4e834a0f2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'of': 2,\n",
              " 'he': 3,\n",
              " 'and': 4,\n",
              " 'a': 5,\n",
              " 'to': 6,\n",
              " 'in': 7,\n",
              " 'his': 8,\n",
              " 'that': 9,\n",
              " 'mallya': 10,\n",
              " 'was': 11,\n",
              " 'with': 12,\n",
              " '—': 13,\n",
              " 'indian': 14,\n",
              " 'for': 15,\n",
              " 'kingfisher': 16,\n",
              " 'india': 17,\n",
              " 'has': 18,\n",
              " 'podcast': 19,\n",
              " 'from': 20,\n",
              " 'as': 21,\n",
              " 'conversation': 22,\n",
              " 'airlines': 23,\n",
              " 'this': 24,\n",
              " 'media': 25,\n",
              " 'how': 26,\n",
              " 'it': 27,\n",
              " 'on': 28,\n",
              " 'while': 29,\n",
              " 'been': 30,\n",
              " 'but': 31,\n",
              " 'life': 32,\n",
              " 'raj': 33,\n",
              " 'shamani': 34,\n",
              " 'mallya’s': 35,\n",
              " 'public': 36,\n",
              " 'into': 37,\n",
              " 'which': 38,\n",
              " 'legal': 39,\n",
              " 'gave': 40,\n",
              " 'conditions': 41,\n",
              " 'authorities': 42,\n",
              " 'being': 43,\n",
              " 'fugitive': 44,\n",
              " 'by': 45,\n",
              " 'he’s': 46,\n",
              " 'brand': 47,\n",
              " '”': 48,\n",
              " 'an': 49,\n",
              " 'four': 50,\n",
              " 'vijay': 51,\n",
              " 'business': 52,\n",
              " 'first': 53,\n",
              " 'massive': 54,\n",
              " 'deep': 55,\n",
              " 'rise': 56,\n",
              " 'fall': 57,\n",
              " 'due': 58,\n",
              " 'luxury': 59,\n",
              " 'financial': 60,\n",
              " 'events': 61,\n",
              " 'support': 62,\n",
              " 'government': 63,\n",
              " 'like': 64,\n",
              " 'state': 65,\n",
              " 'made': 66,\n",
              " 'emotional': 67,\n",
              " 'when': 68,\n",
              " 'label': 69,\n",
              " 'said': 70,\n",
              " 'not': 71,\n",
              " 'no': 72,\n",
              " 'added': 73,\n",
              " 'deeply': 74,\n",
              " 'especially': 75,\n",
              " 'one': 76,\n",
              " 'according': 77,\n",
              " 'him': 78,\n",
              " 'crore': 79,\n",
              " 'all': 80,\n",
              " 'were': 81,\n",
              " 'back': 82,\n",
              " 'exile': 83,\n",
              " 'where': 84,\n",
              " 'far': 85,\n",
              " 'cultural': 86,\n",
              " 'impact': 87,\n",
              " 'calendar': 88,\n",
              " 'mainstream': 89,\n",
              " 'royal': 90,\n",
              " 'challengers': 91,\n",
              " 'bangalore': 92,\n",
              " 'rcb': 93,\n",
              " 'also': 94,\n",
              " 'team': 95,\n",
              " 'expressed': 96,\n",
              " 'return': 97,\n",
              " 'if': 98,\n",
              " 'trial': 99,\n",
              " 'viral': 100,\n",
              " 'groundbreaking': 101,\n",
              " 'episode': 102,\n",
              " '“figuring': 103,\n",
              " 'out': 104,\n",
              " 'sat': 105,\n",
              " 'down': 106,\n",
              " 'unprecedented': 107,\n",
              " 'hour': 108,\n",
              " 'controversial': 109,\n",
              " 'tycoon': 110,\n",
              " 'former': 111,\n",
              " 'owner': 112,\n",
              " 'marked': 113,\n",
              " 'full': 114,\n",
              " 'length': 115,\n",
              " 'appearance': 116,\n",
              " 'nearly': 117,\n",
              " 'nine': 118,\n",
              " 'years': 119,\n",
              " 'generating': 120,\n",
              " 'attention': 121,\n",
              " 'across': 122,\n",
              " 'abroad': 123,\n",
              " 'delves': 124,\n",
              " 'side': 125,\n",
              " 'story': 126,\n",
              " 'much': 127,\n",
              " 'remained': 128,\n",
              " 'unheard': 129,\n",
              " 'prolonged': 130,\n",
              " 'absence': 131,\n",
              " 'ongoing': 132,\n",
              " 'controversies': 133,\n",
              " 'detailed': 134,\n",
              " 'account': 135,\n",
              " 'began': 136,\n",
              " 'vision': 137,\n",
              " 'air': 138,\n",
              " 'travel': 139,\n",
              " 'eventually': 140,\n",
              " 'collapsed': 141,\n",
              " 'under': 142,\n",
              " 'strain': 143,\n",
              " 'pointed': 144,\n",
              " 'combination': 145,\n",
              " 'unfortunate': 146,\n",
              " 'structural': 147,\n",
              " 'issues': 148,\n",
              " 'root': 149,\n",
              " 'causes': 150,\n",
              " 'failure': 151,\n",
              " 'highlighted': 152,\n",
              " '2008': 153,\n",
              " 'global': 154,\n",
              " 'crisis': 155,\n",
              " 'rising': 156,\n",
              " 'fuel': 157,\n",
              " 'costs': 158,\n",
              " 'harsh': 159,\n",
              " 'regulatory': 160,\n",
              " 'lack': 161,\n",
              " 'bodies': 162,\n",
              " 'claimed': 163,\n",
              " 'bureaucratic': 164,\n",
              " 'hurdles': 165,\n",
              " 'needing': 166,\n",
              " 'multiple': 167,\n",
              " 'level': 168,\n",
              " '29': 169,\n",
              " 'chief': 170,\n",
              " 'ministers': 171,\n",
              " 'mentioned': 172,\n",
              " 'impossible': 173,\n",
              " 'streamline': 174,\n",
              " 'operations': 175,\n",
              " 'branded': 176,\n",
              " 'particularly': 177,\n",
              " 'candid': 178,\n",
              " 'discussing': 179,\n",
              " 'economic': 180,\n",
              " 'offender': 181,\n",
              " 'left': 182,\n",
              " 'march': 183,\n",
              " '2016': 184,\n",
              " 'pre': 185,\n",
              " 'scheduled': 186,\n",
              " 'trip': 187,\n",
              " 'abscond': 188,\n",
              " 'took': 189,\n",
              " 'issue': 190,\n",
              " 'called': 191,\n",
              " 'chor': 192,\n",
              " 'thief': 193,\n",
              " 'insisting': 194,\n",
              " 'failed': 195,\n",
              " 'there': 196,\n",
              " 'criminal': 197,\n",
              " 'intent': 198,\n",
              " 'or': 199,\n",
              " 'theft': 200,\n",
              " 'involved': 201,\n",
              " 'hurtful': 202,\n",
              " 'trying': 203,\n",
              " 'settle': 204,\n",
              " 'dues': 205,\n",
              " 'loan': 206,\n",
              " 'repayment': 207,\n",
              " 'battles': 208,\n",
              " 'central': 209,\n",
              " 'points': 210,\n",
              " 'interview': 211,\n",
              " 'claim': 212,\n",
              " 'had': 213,\n",
              " 'several': 214,\n",
              " 'genuine': 215,\n",
              " 'offers': 216,\n",
              " 'banks': 217,\n",
              " 'repay': 218,\n",
              " 'loans': 219,\n",
              " 'between': 220,\n",
              " '2012': 221,\n",
              " '2015': 222,\n",
              " 'proposed': 223,\n",
              " 'settlement': 224,\n",
              " 'deals': 225,\n",
              " '₹14': 226,\n",
              " '000': 227,\n",
              " 'rejected': 228,\n",
              " 'stressed': 229,\n",
              " 'already': 230,\n",
              " 'paid': 231,\n",
              " 'around': 232,\n",
              " '₹6': 233,\n",
              " '200': 234,\n",
              " 'through': 235,\n",
              " 'sale': 236,\n",
              " 'assets': 237,\n",
              " 'other': 238,\n",
              " 'means': 239,\n",
              " 'still': 240,\n",
              " 'questions': 241,\n",
              " 'why': 242,\n",
              " 'are': 243,\n",
              " 'unwilling': 244,\n",
              " 'resolve': 245,\n",
              " 'matter': 246,\n",
              " 'fairly': 247,\n",
              " 'emphasized': 248,\n",
              " 'never': 249,\n",
              " 'intended': 250,\n",
              " 'default': 251,\n",
              " 'wanted': 252,\n",
              " 'resolution': 253,\n",
              " 'believes': 254,\n",
              " 'political': 255,\n",
              " 'motives': 256,\n",
              " 'complicated': 257,\n",
              " 'case': 258,\n",
              " 'describing': 259,\n",
              " 'london': 260,\n",
              " 'admitted': 261,\n",
              " 'despite': 262,\n",
              " 'perception': 263,\n",
              " 'living': 264,\n",
              " 'feels': 265,\n",
              " 'isolated': 266,\n",
              " 'talked': 267,\n",
              " 'about': 268,\n",
              " 'toll': 269,\n",
              " 'away': 270,\n",
              " 'country': 271,\n",
              " 'family': 272,\n",
              " 'saying': 273,\n",
              " 'period': 274,\n",
              " '“loneliest”': 275,\n",
              " 'phase': 276,\n",
              " 'described': 277,\n",
              " 'current': 278,\n",
              " '“semi': 279,\n",
              " 'retired': 280,\n",
              " 'staying': 281,\n",
              " 'busy': 282,\n",
              " 'flamboyant': 283,\n",
              " 'lifestyle': 284,\n",
              " 'once': 285,\n",
              " 'known': 286,\n",
              " 'influence': 287,\n",
              " 'lighter': 288,\n",
              " 'segment': 289,\n",
              " 'looked': 290,\n",
              " 'at': 291,\n",
              " 'proudly': 292,\n",
              " 'noted': 293,\n",
              " 'helped': 294,\n",
              " 'launch': 295,\n",
              " 'careers': 296,\n",
              " 'now': 297,\n",
              " 'superstars': 298,\n",
              " 'deepika': 299,\n",
              " 'padukone': 300,\n",
              " 'katrina': 301,\n",
              " 'kaif': 302,\n",
              " 'branding': 303,\n",
              " 'masterpiece': 304,\n",
              " 'young': 305,\n",
              " 'models': 306,\n",
              " 'glamorous': 307,\n",
              " 'launchpad': 308,\n",
              " 'bollywood': 309,\n",
              " 'fashion': 310,\n",
              " 'world': 311,\n",
              " 'touched': 312,\n",
              " 'ownership': 313,\n",
              " 'ipl': 314,\n",
              " 'shared': 315,\n",
              " 'behind': 316,\n",
              " 'scenes': 317,\n",
              " 'stories': 318,\n",
              " 'managing': 319,\n",
              " 'pride': 320,\n",
              " 'come': 321,\n",
              " 'longer': 322,\n",
              " 'formal': 323,\n",
              " 'association': 324,\n",
              " 'reflected': 325,\n",
              " 'fondly': 326,\n",
              " 'building': 327,\n",
              " 'team’s': 328,\n",
              " 'early': 329,\n",
              " 'fan': 330,\n",
              " 'base': 331,\n",
              " 'will': 332,\n",
              " 'perhaps': 333,\n",
              " 'most': 334,\n",
              " 'significant': 335,\n",
              " 'revelation': 336,\n",
              " \"mallya's\": 337,\n",
              " 'willingness': 338,\n",
              " 'only': 339,\n",
              " 'is': 340,\n",
              " 'assured': 341,\n",
              " 'fair': 342,\n",
              " 'just': 343,\n",
              " 'process': 344,\n",
              " 'does': 345,\n",
              " 'fear': 346,\n",
              " 'facing': 347,\n",
              " 'main': 348,\n",
              " 'concern': 349,\n",
              " 'lies': 350,\n",
              " 'prisons': 351,\n",
              " 'citing': 352,\n",
              " 'uk': 353,\n",
              " 'courts': 354,\n",
              " 'have': 355,\n",
              " 'previously': 356,\n",
              " 'blocked': 357,\n",
              " 'extraditions': 358,\n",
              " 'concerns': 359,\n",
              " 'over': 360,\n",
              " 'jails': 361,\n",
              " 'could': 362,\n",
              " 'guarantee': 363,\n",
              " 'humane': 364,\n",
              " 'unbiased': 365,\n",
              " 'would': 366,\n",
              " 'seriously': 367,\n",
              " 'consider': 368,\n",
              " 'returning': 369,\n",
              " 'clear': 370,\n",
              " 'name': 371,\n",
              " 'reaction': 372,\n",
              " 'went': 373,\n",
              " 'almost': 374,\n",
              " 'instantly': 375,\n",
              " 'millions': 376,\n",
              " 'views': 377,\n",
              " 'within': 378,\n",
              " '24': 379,\n",
              " 'hours': 380,\n",
              " 'social': 381,\n",
              " 'users': 382,\n",
              " 'split': 383,\n",
              " 'some': 384,\n",
              " 'newfound': 385,\n",
              " 'sympathy': 386,\n",
              " 'praised': 387,\n",
              " 'hosting': 388,\n",
              " 'such': 389,\n",
              " 'fearless': 390,\n",
              " 'others': 391,\n",
              " 'criticized': 392,\n",
              " 'platforming': 393,\n",
              " 'someone': 394,\n",
              " 'declared': 395,\n",
              " 'comedians': 396,\n",
              " 'influencers': 397,\n",
              " 'jumped': 398,\n",
              " 'parodies': 399,\n",
              " 'takes': 400,\n",
              " 'emerging': 401,\n",
              " 'corners': 402,\n",
              " 'internet': 403,\n",
              " 'essence': 404,\n",
              " 'platform': 405,\n",
              " 'present': 406,\n",
              " 'version': 407,\n",
              " 'something': 408,\n",
              " 'claims': 409,\n",
              " 'long': 410,\n",
              " 'denied': 411,\n",
              " 'leap': 412,\n",
              " 'credibility': 413,\n",
              " 'creator': 414,\n",
              " 'interviewer': 415,\n",
              " 'signaling': 416,\n",
              " 'new': 417,\n",
              " 'era': 418,\n",
              " 'digital': 419,\n",
              " 'platforms': 420,\n",
              " 'can': 421,\n",
              " 'rival': 422,\n",
              " 'traditional': 423,\n",
              " 'journalism': 424,\n",
              " 'depth': 425,\n",
              " 'access': 426,\n",
              " 'reach': 427}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = []\n",
        "\n",
        "for i in podcast.split(\".\"):\n",
        "  tokenized_sequence = token.texts_to_sequences([i])[0]\n",
        "\n",
        "  for j in range(1, len(tokenized_sequence)):\n",
        "    input_sequence.append(tokenized_sequence[:j+1])"
      ],
      "metadata": {
        "id": "wVpr5-xxiYKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequence])"
      ],
      "metadata": {
        "id": "OVq33arFj6NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JadQcyufkElo",
        "outputId": "36d68a5c-37b6-4ec2-bd86-92f34e8064ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "q8OsJGSKjnGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pdded_sequence = pad_sequences([input_sequence], maxlen = max_len, padding = \"pre\") Both works\n",
        "\n",
        "pdded_sequence = pad_sequences(input_sequence, maxlen = max_len, padding = \"pre\")"
      ],
      "metadata": {
        "id": "7d70ap4PjyoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdded_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx6_KsNOkKGh",
        "outputId": "dd441c61-7a0f-4ef6-8d74-4636d6f1b7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   7,   5],\n",
              "       [  0,   0,   0, ...,   7,   5, 101],\n",
              "       [  0,   0,   0, ...,   5, 101, 102],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   7, 425, 426],\n",
              "       [  0,   0,   0, ..., 425, 426,   4],\n",
              "       [  0,   0,   0, ..., 426,   4, 427]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pdded_sequence[:,:-1]\n",
        "y = pdded_sequence[:,-1]"
      ],
      "metadata": {
        "id": "cJOglrQAkO8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pv43XoOkkhB",
        "outputId": "8e202f94-f5cf-411a-e302-9632d1967328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y.shape\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ELN045bkmXi",
        "outputId": "eedd2661-057d-4a0e-edc7-aa331503610a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  5, 101, 102,   2,   8,  19, 103, 104,  48,  33,  34, 105, 106,\n",
              "        15,  49, 107,  50, 108,  22,  12,  51,  10,  13,   1, 109,  52,\n",
              "       110,   4, 111, 112,   2,  16,  23, 113,  35,  53, 114, 115,  36,\n",
              "       116,   7, 117, 118, 119, 120,  54, 121, 122,  17,   4, 123,  19,\n",
              "       124,  55,  37,  35,  56,  57,   4,   8, 125,   2,   1, 126,  13,\n",
              "       127,   2,  38,  18, 128, 129,  58,   6,   8, 130, 131,  20,  14,\n",
              "        25,   4,   1, 132,  39, 133,   4,  57,   2,  16,  23,  10,  40,\n",
              "         5, 134, 135,   2,  26,  16,  23,  38, 136,  12,   5, 137,   2,\n",
              "        59, 138, 139,   7,  17, 140, 141, 142,  60, 143, 144,   6,   5,\n",
              "       145,   2, 146,  61,   4, 147, 148,  21,   1, 149, 150,   2,   1,\n",
              "       151, 152,   1, 153, 154,  60, 155, 156, 157, 158, 159, 160,  41,\n",
              "         7,  17,   4,   5, 161,   2,  62,  20,  63, 162, 163,   9, 164,\n",
              "       165,  64, 166,   1,  62,   2, 167,  65, 168,  42, 169, 170, 171,\n",
              "        21,   3, 172,  66,  27, 173,   6, 174, 175,  43, 176,   5,  44,\n",
              "        10,  11, 177,  67,   4, 178,  68, 179,   8,  69,  21,   5,  44,\n",
              "       180, 181,  70,   3, 182,  17,   7, 183, 184,  15,   5, 185, 186,\n",
              "        52, 187,  71,   6, 188, 189, 190,  12,  43, 191,   5, 192, 193,\n",
              "        45,  25,   4,   1,  36, 194,   9,  29,   1,  23, 195, 196,  11,\n",
              "        72, 197, 198, 199, 200, 201,  73,   9,  24,  69,  18,  30,  74,\n",
              "       202,  75,  68,  46,  30, 203,   6, 204, 205, 207,  39, 208,  76,\n",
              "         2,   1, 209, 210,   2,   1, 211,  11,  35, 212,   9,   3, 213,\n",
              "        66, 214, 215, 216,   6,  14, 217,   6, 218,   1, 219,   6,  78,\n",
              "       220, 221,   4, 222,   3, 223,  50, 224, 225,  13,  76,   2,  38,\n",
              "        11,  15, 226, 227,  79,  13,  31,  80,  81, 228, 229,   9,   3,\n",
              "        18, 230, 231,  82, 232, 233, 234,  79, 235,   1, 236,   2, 237,\n",
              "         4, 238, 239,   4, 240, 241, 242,   1,  14,  42, 243, 244,   6,\n",
              "       245,   1, 246, 247, 248,   9,   3, 249, 250,   6, 251,   4, 252,\n",
              "         5, 253,  31,   3, 254, 255, 256, 257,   1, 258,   7,  83, 259,\n",
              "         8,  32,   7, 260,  10, 261,   9, 262,   1, 263,   2, 264,   7,\n",
              "        59,   3, 265,  74, 266, 267, 268,   1,  67, 269,   2,  43, 270,\n",
              "        20,   8, 271,   4, 272, 273,  24, 274,   2,  83,  18,  30,   1,\n",
              "       275, 276,   2,   8,  32, 277,   8, 278,  32,  21, 279, 280,  48,\n",
              "        84,  46, 281, 282,  31,  85,  20,   1, 283, 284,   3,  11, 285,\n",
              "       286,  15, 287,   1,  16,  47,   7,   5, 288, 289,   2,   1,  19,\n",
              "        10, 290,  82, 291,   1,  86,  87,   2,   1,  16,  47,  75,   1,\n",
              "        16,  88, 292, 293,  26,  27, 294, 295,   1, 296,   2, 297, 298,\n",
              "        64, 299, 300,   4, 301, 302,   6,  78,   1,  88,  11,   5, 303,\n",
              "       304,   9,  40, 305, 306,   5, 307,  89, 308,  37, 309,   4,   1,\n",
              "       310, 311,  90,  91,  92,  93,   1,  22,  94, 312,  28,   8, 313,\n",
              "         2,   1, 314,  95,  90,  91,  92, 315, 316,   1, 317, 318,   2,\n",
              "       319,   1,  95,   4,  96, 320,   7,  26,  85,  27,  18, 321,   3,\n",
              "        72, 322,  18,   5, 323, 324,  12,  93,   3, 325, 326,  28, 327,\n",
              "         1, 328, 329,  47,   4, 330, 331,   3,  97,   6,  17, 333,   1,\n",
              "       334, 335, 336,  11, 337, 338,   6,  97,   6,  17,  13,  31, 339,\n",
              "        98,   3, 340, 341,   2,   5, 342,   4, 343,  39, 344,  70,   9,\n",
              "        29,   3, 345,  71, 346, 347,  99,   8, 348, 349, 350,  12,   1,\n",
              "        41,   2,  14, 351, 352,  26, 353, 354, 355, 356, 357, 358,  58,\n",
              "         6, 359, 360,   1,  65,   2,  14, 361,  73,   9,  98,   1,  14,\n",
              "        63, 362, 363, 364,  41,   4,  49, 365,  99,   3, 366, 367, 368,\n",
              "       369,   6, 370,   8, 371, 372,   4,  87,   1,  19, 373, 100, 374,\n",
              "       375,  12, 376,   2, 377, 378,   1,  53, 379, 380,  25, 382,  81,\n",
              "       383,  13,  29, 384,  96, 385, 386,   4, 387,  33,  34,  15, 388,\n",
              "       389,   5, 390,   4,  55,  22, 391, 392,   1, 393,   2, 394, 395,\n",
              "         5,  44,  45,  14,  42,   4, 397,  94, 398,  37,   1,  22,  12,\n",
              "       100, 399,   4, 400, 401,  20,  80, 402,   2,   1, 403, 404,  24,\n",
              "        19,  40,  51,  10,   1, 405,   6, 406,   8, 407,   2,  61,  13,\n",
              "       408,   3, 409,  46, 410,  30, 411,  45,  89,  25,  33,  34,  27,\n",
              "        11,   5,  54, 412,   7, 413,  21,   5, 414,   4, 415, 416,   5,\n",
              "       417, 418,  84, 419, 420, 421, 422, 423, 424,   7, 425, 426,   4,\n",
              "       427], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Zl0LZrEElfKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=len(token.word_index)+1)"
      ],
      "metadata": {
        "id": "BI3938kJlfNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding"
      ],
      "metadata": {
        "id": "ru9Zx01fkoFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "2SPbqaEdl9YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Embedding(input_dim = len(token.word_index)+1, output_dim = 150, input_length=max_len-1))\n",
        "model.add(LSTM(200))\n",
        "model.add(Dense(len(token.word_index)+1, activation=\"softmax\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8j3S7FClHIC",
        "outputId": "66e06723-42d3-42f1-8a8d-86df2d635150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "rho5yYnDmGHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLHx0V6qmKad",
        "outputId": "aa5c22c4-1537-459d-90c4-dceacd6e1be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.0267 - loss: 6.0185\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.0555 - loss: 5.6180\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.0460 - loss: 5.6126\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.0534 - loss: 5.5319\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.0577 - loss: 5.3862\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.0618 - loss: 5.3219\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.0618 - loss: 5.2043\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.0946 - loss: 5.0093\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.0911 - loss: 4.8755\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.1154 - loss: 4.5496\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.1593 - loss: 4.1364\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.2014 - loss: 3.8612\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.2515 - loss: 3.4948\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.2967 - loss: 3.1844\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.3698 - loss: 2.8719\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.4710 - loss: 2.5711\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.5616 - loss: 2.3114\n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.6367 - loss: 2.0329\n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - accuracy: 0.6789 - loss: 1.7632\n",
            "Epoch 20/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.7808 - loss: 1.5901\n",
            "Epoch 21/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.8199 - loss: 1.4292\n",
            "Epoch 22/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.8570 - loss: 1.2635\n",
            "Epoch 23/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.8934 - loss: 1.1111\n",
            "Epoch 24/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 130ms/step - accuracy: 0.9246 - loss: 0.9818\n",
            "Epoch 25/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9358 - loss: 0.8933\n",
            "Epoch 26/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9414 - loss: 0.8091\n",
            "Epoch 27/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9561 - loss: 0.7243\n",
            "Epoch 28/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9648 - loss: 0.6482\n",
            "Epoch 29/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9589 - loss: 0.6154\n",
            "Epoch 30/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9708 - loss: 0.5386\n",
            "Epoch 31/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9689 - loss: 0.4840\n",
            "Epoch 32/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9614 - loss: 0.4632\n",
            "Epoch 33/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.9799 - loss: 0.4075\n",
            "Epoch 34/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.9815 - loss: 0.3585\n",
            "Epoch 35/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9653 - loss: 0.3669\n",
            "Epoch 36/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.9701 - loss: 0.3444\n",
            "Epoch 37/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9764 - loss: 0.3056\n",
            "Epoch 38/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.9779 - loss: 0.2931\n",
            "Epoch 39/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.9746 - loss: 0.2749\n",
            "Epoch 40/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9780 - loss: 0.2501\n",
            "Epoch 41/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9790 - loss: 0.2218\n",
            "Epoch 42/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9808 - loss: 0.2187\n",
            "Epoch 43/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9761 - loss: 0.2182\n",
            "Epoch 44/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9779 - loss: 0.2102\n",
            "Epoch 45/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.9790 - loss: 0.1990\n",
            "Epoch 46/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.9870 - loss: 0.1823\n",
            "Epoch 47/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.9719 - loss: 0.1982\n",
            "Epoch 48/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.9802 - loss: 0.1678\n",
            "Epoch 49/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.9773 - loss: 0.1643\n",
            "Epoch 50/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.9802 - loss: 0.1488\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79c86ee12d50>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction time\n",
        "\n",
        "text = \"Rise and Fall of Kingfisher Airlines\"\n",
        "# tokenizing\n",
        "import time\n",
        "\n",
        "for i in range(10):\n",
        "  token_txt = token.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_txt = pad_sequences([token_txt],maxlen=max_len-1,padding=\"pre\")\n",
        "  # predict\n",
        "  import numpy as np\n",
        "  pos = np.argmax(model.predict(padded_txt))\n",
        "\n",
        "\n",
        "  for word,index in token.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(1)"
      ],
      "metadata": {
        "id": "UixKF-BLmO-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P9aOVX4RnT1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l1HffBvMpsdL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
